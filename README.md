# ğŸ“š Ensemble Methods and Boosting Examples

This repository presents a curated selection of ensemble learning techniques, focusing on baseline classifiers, tree-based models, and hyperparameter optimization.

## ğŸ“‚ Structure

- `data/` : Contains datasets used in the notebooks (if any).
- `notebooks/` : Jupyter Notebooks demonstrating each major topic.
- `LICENSE` : Project license information (MIT License).
- `.gitignore` : Files and directories to ignore in version control.

## ğŸ“– Projects Overview

| Notebook | Description |
|:---|:---|
| [01_classification_baselines.ipynb](notebooks/01_classification_baselines.ipynb) | Implementation of Gaussian Naive Bayes, K-Nearest Neighbors, and Logistic Regression. Hyperparameter tuning and validation curve analysis included. |
| [02_tree_based_models_and_bagging.ipynb](notebooks/02_tree_based_models_and_bagging.ipynb) | Decision Tree and Random Forest classifiers with hyperparameter optimization using Grid Search and Cross-Validation. Discussion of bias-variance tradeoff and class balancing. |

## ğŸ› ï¸ Key Skills Demonstrated

- Classification modeling
- Hyperparameter tuning with Grid Search
- Handling class imbalance
- Bias-variance analysis
- Ensemble learning principles

## ğŸ“œ License

This project is licensed under the MIT License - see the LICENSE file for details.
